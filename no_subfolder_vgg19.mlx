clear all;
close all;

inputsize_row = 405;
inputsize_col = 720;
channel = 3;

inputsize = [inputsize_row, inputsize_col];
imagesize = [inputsize_row, inputsize_col, channel];
imds = imageDatastore('C:\Users\1\all_in_one_trainning\', 'IncludeSubfolders' ,true, 'LabelSource', 'foldernames');

a=categorical({'vignas'})
b=categorical({'crasan'})
c=categorical({'sobvig'})
d=categorical({'soboro'})
e=categorical({'muffin'})
f=categorical({'goroke'})
for i=1 : 102
imds.Labels(i,1)=repmat(a, size(imds.Labels(i,1), 1), 1)
end
for i=103: 204
imds.Labels(i,1)=repmat(b, size(imds.Labels(i,1), 1), 1)
end
for i=205: 306
imds.Labels(i,1)=repmat(c, size(imds.Labels(i,1), 1), 1)
end
for i=307:408
imds.Labels(i,1)=repmat(d, size(imds.Labels(i,1), 1), 1)
end
for i=409:510
imds.Labels(i,1)=repmat(e, size(imds.Labels(i,1), 1), 1)
end
for i=511:612
imds.Labels(i,1)=repmat(f, size(imds.Labels(i,1), 1), 1)
end%size*1배열 반환
imgs = readall(imds);
T=imds.countEachLabel;


% training data
imds.countEachLabel;
no_sample = imds.countEachLabel.Count(1)*length(imds.countEachLabel.Label);
res_imgs = zeros(inputsize_row, inputsize_col, channel, no_sample);

for i=1 : no_sample
    res_imgs(:, :, :, i) = imresize(imgs{i}, inputsize);
end


XTrain = res_imgs;
YTrain = categorical(imds.Labels);
no_Validation = round(no_sample*0.2);
idx = randperm(size(XTrain, 4), no_Validation);
XValidation = XTrain(:, :, :, idx);
XTrain(:, :, :, idx) = [];
YValidation = YTrain(idx);
YTrain(idx)= [];


imageAugmentor = imageDataAugmenter('RandRotation', [-20, 20], 'RandXTranslation', [-3 3], 'RandYTranslation', [-3 3]);
augimdsTrain = augmentedImageDatastore(imagesize, XTrain, YTrain, 'DataAugmentation', imageAugmentor);
augimdsValidation = augmentedImageDatastore(imagesize, XValidation, YValidation, 'DataAugmentation', imageAugmentor);


layers = [
    imageInputLayer([inputsize_row inputsize_col 3],"Name","data")
    convolution2dLayer([11 11],96,"Name","conv1","BiasLearnRateFactor",2,"Stride",[4 4])
    crossChannelNormalizationLayer(5,"Name","norm1","K",1)
    maxPooling2dLayer([3 3],"Name","pool1","Stride",[2 2])
    reluLayer("Name","relu1")
    groupedConvolution2dLayer([5 5],128,2,"Name","conv2","BiasLearnRateFactor",2,"Padding",[2 2 2 2])
    crossChannelNormalizationLayer(5,"Name","norm2","K",1)
    maxPooling2dLayer([3 3],"Name","pool2","Stride",[2 2])
    reluLayer("Name","relu2")
    convolution2dLayer([3 3],384,"Name","conv3","BiasLearnRateFactor",2,"Padding",[1 1 1 1])
    reluLayer("Name","relu3")
    groupedConvolution2dLayer([3 3],192,2,"Name","conv4","BiasLearnRateFactor",2,"Padding",[1 1 1 1])
    reluLayer("Name","relu4")
    groupedConvolution2dLayer([3 3],128,2,"Name","conv5","BiasLearnRateFactor",2,"Padding",[1 1 1 1])
    maxPooling2dLayer([3 3],"Name","pool5","Stride",[2 2])
    reluLayer("Name","relu5")
    fullyConnectedLayer(4096,"Name","fc6","BiasLearnRateFactor",2)
    reluLayer("Name","relu6")
    dropoutLayer(0.5,"Name","drop6")
    fullyConnectedLayer(4096,"Name","fc7","BiasLearnRateFactor",2)
    reluLayer("Name","relu7")
    dropoutLayer(0.5,"Name","drop7")
    fullyConnectedLayer(7,"Name","fc")
    softmaxLayer("Name","prob")
    classificationLayer("Name","classoutput")];

%plot(layerGraph(layers));

options = trainingOptions('adam', ... %-mommentum 포함된 sgd / 'adam'(rmsprop+mommentum)과 learning rate 사용 고려
    'MiniBatchSize' , 10, ...
    'MaxEpochs', 25, ...
    'Shuffle','every-epoch', ...
    'InitialLearnRate', 1e-4, ...
     'ValidationData',{XValidation YValidation}, ...
    'ValidationFrequency', 10, ...
    'Verbose',false, ...
    'Plots','training-progress');%sgdm-finalvalidationaccuracy 95.6
                                 %amdam-finalvalidationaccuracy 93.8


[convnet, trainInfo] = trainNetwork(XTrain, YTrain, layers, options)


save another_vgg19.mat convnet;
save vgg19_info.mat trainInfo;
analyzeNetwork(convnet);


load another_vgg19.mat
YPred = classify(convnet, XValidation);
accuracy = sum(YPred == YValidation)/numel(YValidation)

test_imds = imageDatastore('C:\Users\1\test_all\',  'IncludeSubfolders', true, 'LabelSource', 'foldernames');
a=categorical({'vignas'})
b=categorical({'crasan'})
c=categorical({'sobvig'})
d=categorical({'soboro'})
e=categorical({'muffin'})
f=categorical({'goroke'})
for i=1 : 15
test_imds.Labels(i,1)=repmat(a, size(test_imds.Labels(i,1), 1), 1)
end
for i=16: 29
test_imds.Labels(i,1)=repmat(b, size(test_imds.Labels(i,1), 1), 1)
end
for i=30: 44
test_imds.Labels(i,1)=repmat(c, size(test_imds.Labels(i,1), 1), 1)
end
for i=45:59
test_imds.Labels(i,1)=repmat(d, size(test_imds.Labels(i,1), 1), 1)
end
for i=60:74
test_imds.Labels(i,1)=repmat(e, size(test_imds.Labels(i,1), 1), 1)
end
for i=75:90
test_imds.Labels(i,1)=repmat(f, size(test_imds.Labels(i,1), 1), 1)
end
test_imgs = readall(test_imds);

%test data
testsize_row = 720;
testtsize_col = 1440;
test_imds.countEachLabel;
no_testsample = test_imds.countEachLabel.Count(1)*length(test_imds.countEachLabel.Label);
res_testimgs = zeros(inputsize_row, inputsize_col, channel, no_testsample);

for i=1 : no_testsample
    res_testimgs(:, :, :, i) = imresize(test_imgs{i}, inputsize);
end

XTest = res_testimgs;
YTest = categorical(test_imds.Labels);

YPred_Test = classify(convnet, XTest);
accuracy = sum(YPred_Test == YTest)/numel(YTest)%Ytest의 개수 반환
test_a=sum(YPred_Test==YTest)%맞힌갯수
test_b=sum(YPred_Test~=YTest)%틀린갯수
