clear all;
close all;

inputsize_row = 405;
inputsize_col = 720;
channel = 3;

inputsize = [inputsize_row, inputsize_col];
imagesize = [inputsize_row, inputsize_col, channel];
imds = imageDatastore('C:\Users\1\training',  'IncludeSubfolders', true, 'LabelSource', 'foldernames');
imgs = readall(imds);


% training data
imds.countEachLabel;
no_sample = imds.countEachLabel.Count(1)*length(imds.countEachLabel.Label);
res_imgs = zeros(inputsize_row, inputsize_col, channel, no_sample);

for i=1 : no_sample
    res_imgs(:, :, :, i) = imresize(imgs{i}, inputsize);
end


XTrain = res_imgs;
YTrain = categorical(imds.Labels);
no_Validation = no_sample*0.2;
idx = randperm(size(XTrain, 4), no_Validation);
XValidation = XTrain(:, :, :, idx);
XTrain(:, :, :, idx) = [];
YValidation = YTrain(idx);
YTrain(idx)= [];


imageAugmentor = imageDataAugmenter('RandRotation', [-20, 20], 'RandXTranslation', [-3 3], 'RandYTranslation', [-3 3]);
augimdsTrain = augmentedImageDatastore(imagesize, XTrain, YTrain, 'DataAugmentation', imageAugmentor);
augimdsValidation = augmentedImageDatastore(imagesize, XValidation, YValidation, 'DataAugmentation', imageAugmentor);


layers = [
    imageInputLayer([inputsize_row inputsize_col 3],"Name","data")
    convolution2dLayer([11 11],96,"Name","conv1","BiasLearnRateFactor",2,"Stride",[4 4])
    crossChannelNormalizationLayer(5,"Name","norm1","K",1)
    maxPooling2dLayer([3 3],"Name","pool1","Stride",[2 2])
    reluLayer("Name","relu1")
    groupedConvolution2dLayer([5 5],128,2,"Name","conv2","BiasLearnRateFactor",2,"Padding",[2 2 2 2])
    crossChannelNormalizationLayer(5,"Name","norm2","K",1)
    maxPooling2dLayer([3 3],"Name","pool2","Stride",[2 2])
    reluLayer("Name","relu2")
    convolution2dLayer([3 3],384,"Name","conv3","BiasLearnRateFactor",2,"Padding",[1 1 1 1])
    reluLayer("Name","relu3")
    groupedConvolution2dLayer([3 3],192,2,"Name","conv4","BiasLearnRateFactor",2,"Padding",[1 1 1 1])
    reluLayer("Name","relu4")
    groupedConvolution2dLayer([3 3],128,2,"Name","conv5","BiasLearnRateFactor",2,"Padding",[1 1 1 1])
    maxPooling2dLayer([3 3],"Name","pool5","Stride",[2 2])
    reluLayer("Name","relu5")
    fullyConnectedLayer(4096,"Name","fc6","BiasLearnRateFactor",2)
    reluLayer("Name","relu6")
    dropoutLayer(0.5,"Name","drop6")
    fullyConnectedLayer(4096,"Name","fc7","BiasLearnRateFactor",2)
    reluLayer("Name","relu7")
    dropoutLayer(0.5,"Name","drop7")
    fullyConnectedLayer(6,"Name","fc")
    softmaxLayer("Name","prob")
    classificationLayer("Name","classoutput")];

options = trainingOptions('adam', ... %-mommentum 포함된 sgd / 'adam'(rmsprop+mommentum)과 learning rate 사용 고려
    'MiniBatchSize' , 10, ...
    'MaxEpochs', 15, ...
    'Shuffle','every-epoch', ...
    'InitialLearnRate', 1e-4, ...
     'ValidationData',{XValidation YValidation}, ...
    'ValidationFrequency', 10, ...
    'Verbose',false, ...
    'Plots','training-progress');%sgdm-finalvalidationaccuracy 95.6
                                 %amdam-finalvalidationaccuracy 93.8


[convnet, trainInfo] = trainNetwork(XTrain, YTrain, layers, options)


save convnet_vgg19.mat convnet;
save vgg19_info.mat trainInfo;
analyzeNetwork(convnet);

Validation 
load convnet_vgg19.mat
YPred = classify(convnet, XValidation);
accuracy = sum(YPred == YValidation)/numel(YValidation)

test_imds = imageDatastore('C:\Users\1\test',  'IncludeSubfolders', true, 'LabelSource', 'filenames');
test_imgs = readall(test_imds);

%test data
testsize_row = 720;
testtsize_col = 1440;
test_imds.countEachLabel;
no_testsample = test_imds.countEachLabel.Count(1)*length(test_imds.countEachLabel.Label);
res_testimgs = zeros(inputsize_row, inputsize_col, channel, no_testsample);

for i=1 : no_testsample
    res_testimgs(:, :, :, i) = imresize(test_imgs{i}, inputsize);
end

XTest = res_testimgs;
YTest = categorical(test_imds.Labels);

YPred_Test = classify(convnet, XTest);
accuracy = sum(YPred_Test == YTest)/numel(YTest)
